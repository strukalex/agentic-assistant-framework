# Database Configuration
DATABASE_URL=postgresql+asyncpg://postgres:postgres@localhost:5432/paias
DATABASE_POOL_SIZE=5
DATABASE_MAX_OVERFLOW=10

# OpenTelemetry Configuration
OTEL_EXPORTER_OTLP_ENDPOINT=http://localhost:4317
OTEL_SERVICE_NAME=paias
OTEL_SAMPLING_RATE=1.0

# Vector Search Configuration
VECTOR_DIMENSION=1536
HNSW_EF_SEARCH=40

# === Agent / LLM Configuration (Phase 1 Spec 2) ===
# Default model: DeepSeek 3.2 via Microsoft Azure AI Foundry
AZURE_AI_FOUNDRY_ENDPOINT=
AZURE_AI_FOUNDRY_API_KEY=
AZURE_DEPLOYMENT_NAME=DeepSeek-V3.2
OPENAI_API_VERSION=2024-10-21

# LLM behavior tuning
LLM_TEMPERATURE=             # 0.0=deterministic, 2.0=max creativity
LLM_MAX_TOKENS=              # Leave empty for model default, or set explicit limit (e.g., 4096)
MCP_RESULT_MAX_LENGTH=       # Max chars for MCP tool results before truncation (increase if model truncates too much)

# === Web Search MCP Configuration (Phase 1 Spec 2) ===
# Open-WebSearch MCP server (via `npx -y @open-websearch/mcp-server`)
WEBSEARCH_ENGINE=duckduckgo
WEBSEARCH_MAX_RESULTS=10
WEBSEARCH_TIMEOUT_SECONDS=30

# === Windmill ===
WINDMILL_BASE_URL=http://localhost:8000  # Your Windmill instance
WINDMILL_WORKSPACE=default
WINDMILL_TOKEN=<your-token>
WINDMILL_FLOW_PATH=research/daily_research  # Path where flow is registered

# OTHER
ENABLE_AGENTIC_LOGGING=false # detailed logging
AGENTIC_LOGGING_VERBOSE=false # full json logs for request/response data