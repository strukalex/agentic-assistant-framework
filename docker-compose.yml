services:
  postgres:
    image: pgvector/pgvector:pg17  # Use official pgvector image with PostgreSQL 17
    environment:
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres
      POSTGRES_DB: paias
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      # Mount init scripts to create additional databases (e.g., windmill)
      - ./docker/postgres/init:/docker-entrypoint-initdb.d:ro
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 10s
      timeout: 5s
      retries: 5

  jaeger:
    image: jaegertracing/all-in-one:latest
    environment:
      COLLECTOR_OTLP_ENABLED: "true"
    ports:
      - "16686:16686"
      - "4317:4317"
      - "4318:4318"
    healthcheck:
      test: ["CMD", "wget", "--spider", "-q", "http://localhost:16686"]
      interval: 10s
      timeout: 5s
      retries: 5

  # ============================================================================
  # Loki + Grafana (Centralized Logging via OTLP)
  # ============================================================================
  # Loki: Log aggregation system with native OTLP support
  # Grafana: Visualization UI at http://localhost:3000
  # Workers send logs directly to Loki via OTLP endpoint
  # ============================================================================

  loki:
    image: grafana/loki:3.0.0
    ports:
      - "3100:3100"
    command: -config.file=/etc/loki/local-config.yaml
    volumes:
      - loki_data:/loki

  grafana:
    image: grafana/grafana:latest
    ports:
      - "3000:3000"
    environment:
      - GF_AUTH_ANONYMOUS_ENABLED=true
      - GF_AUTH_ANONYMOUS_ORG_ROLE=Admin
    volumes:
      - grafana_data:/var/lib/grafana
    depends_on:
      - loki

  # ============================================================================
  # Windmill Orchestration (Spec 003)
  # ============================================================================
  # Windmill provides workflow orchestration with:
  # - DAG-based execution for linear/parallel steps
  # - Human-in-the-loop approval gates (suspend/resume)
  # - Resource limits per worker (1 CPU, 2GB memory per FR-010)
  # - Job scheduling and monitoring UI
  #
  # Startup sequence:
  # 1. postgres must be healthy first
  # 2. windmill_server starts and creates schema
  # 3. windmill_worker connects and processes jobs
  # ============================================================================

  windmill_server:
    image: ghcr.io/windmill-labs/windmill:main
    pull_policy: always
    restart: unless-stopped
    ports:
      - "8100:8000"  # Windmill UI at http://localhost:8100
    environment:
      # Database connection (uses same postgres instance)
      DATABASE_URL: postgres://postgres:postgres@postgres:5432/windmill?sslmode=disable
      # Base URL for webhooks and resume URLs
      BASE_URL: http://localhost:8100
      # Disable email (not needed for local dev)
      RUST_LOG: info
      # Server mode
      MODE: server
    depends_on:
      postgres:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/api/version"]
      interval: 10s
      timeout: 5s
      retries: 10
      start_period: 30s

  windmill_worker:
    build:
      context: .
      dockerfile: Dockerfile.windmill
    image: paias-windmill-worker:latest
    restart: unless-stopped
    environment:
      DATABASE_URL: postgres://postgres:postgres@postgres:5432/windmill?sslmode=disable
      BASE_URL: http://localhost:8100
      RUST_LOG: warn
      MODE: worker
      WORKER_GROUP: default
      # Tell Windmill to use pre-installed paias package and system site-packages
      ADDITIONAL_PYTHON_PATHS: "/app:/usr/local/lib/python3.11/dist-packages"
      # WHITELIST_ENVS: Comma-separated list of env vars to pass to Python scripts
      # This is required because Windmill isolates script execution
      WHITELIST_ENVS: "AZURE_AI_FOUNDRY_ENDPOINT,AZURE_AI_FOUNDRY_API_KEY,AZURE_DEPLOYMENT_NAME,AZURE_API_VERSION,PAIAS_DATABASE_URL,OTEL_EXPORTER_OTLP_ENDPOINT,OTEL_EXPORTER_OTLP_LOGS_ENDPOINT,OTEL_EXPORTER_OTLP_TRACES_ENDPOINT,OTEL_SERVICE_NAME,OTEL_SAMPLING_RATE,WEBSEARCH_ENGINE,WEBSEARCH_MAX_RESULTS,WEBSEARCH_TIMEOUT_SECONDS,ENABLE_AGENTIC_LOGGING"
      # Pass through Azure AI Foundry credentials (from .env)
      AZURE_AI_FOUNDRY_ENDPOINT: ${AZURE_AI_FOUNDRY_ENDPOINT}
      AZURE_AI_FOUNDRY_API_KEY: ${AZURE_AI_FOUNDRY_API_KEY}
      AZURE_DEPLOYMENT_NAME: ${AZURE_DEPLOYMENT_NAME:-gpt-4o}
      AZURE_API_VERSION: ${OPENAI_API_VERSION:-2024-12-01-preview}
      # Database URL for paias application (use Docker service name, not localhost)
      # Separate from Windmill's DATABASE_URL to avoid conflicts
      PAIAS_DATABASE_URL: postgresql+asyncpg://postgres:postgres@postgres:5432/paias
      # Telemetry - traces go to Jaeger, logs go to Loki
      OTEL_EXPORTER_OTLP_ENDPOINT: http://jaeger:4317
      OTEL_EXPORTER_OTLP_TRACES_ENDPOINT: http://jaeger:4317
      OTEL_EXPORTER_OTLP_LOGS_ENDPOINT: http://loki:3100/otlp/v1/logs
      OTEL_SERVICE_NAME: ${OTEL_SERVICE_NAME:-paias}
      OTEL_SAMPLING_RATE: ${OTEL_SAMPLING_RATE:-1.0}
      # Web search configuration
      WEBSEARCH_ENGINE: ${WEBSEARCH_ENGINE:-duckduckgo}
      WEBSEARCH_MAX_RESULTS: ${WEBSEARCH_MAX_RESULTS:-10}
      WEBSEARCH_TIMEOUT_SECONDS: ${WEBSEARCH_TIMEOUT_SECONDS:-30}
      # Logging - enabled to send logs to Loki via OTLP
      ENABLE_AGENTIC_LOGGING: "true"
    depends_on:
      windmill_server:
        condition: service_healthy
      jaeger:
        condition: service_healthy
      loki:
        condition: service_started
    # Resource limits per FR-010 (Constitution Article II.F)
    deploy:
      resources:
        limits:
          cpus: "1.0"
          memory: 2G
        reservations:
          cpus: "0.5"
          memory: 1G
    volumes:
      # Worker cache
      - windmill_worker_cache:/tmp/windmill/cache

  # Optional: Additional worker for parallel execution
  windmill_worker_2:
    build:
      context: .
      dockerfile: Dockerfile.windmill
    image: paias-windmill-worker:latest
    restart: unless-stopped
    profiles:
      - scale  # Only starts with: docker compose --profile scale up
    environment:
      DATABASE_URL: postgres://postgres:postgres@postgres:5432/windmill?sslmode=disable
      BASE_URL: http://localhost:8100
      RUST_LOG: warn
      MODE: worker
      WORKER_GROUP: default
      # Tell Windmill to use pre-installed paias package and system site-packages
      ADDITIONAL_PYTHON_PATHS: "/app:/usr/local/lib/python3.11/dist-packages"
      # WHITELIST_ENVS: Comma-separated list of env vars to pass to Python scripts
      WHITELIST_ENVS: "AZURE_AI_FOUNDRY_ENDPOINT,AZURE_AI_FOUNDRY_API_KEY,AZURE_DEPLOYMENT_NAME,AZURE_API_VERSION,PAIAS_DATABASE_URL,OTEL_EXPORTER_OTLP_ENDPOINT,OTEL_EXPORTER_OTLP_LOGS_ENDPOINT,OTEL_EXPORTER_OTLP_TRACES_ENDPOINT,OTEL_SERVICE_NAME,OTEL_SAMPLING_RATE,WEBSEARCH_ENGINE,WEBSEARCH_MAX_RESULTS,WEBSEARCH_TIMEOUT_SECONDS,ENABLE_AGENTIC_LOGGING"
      # Pass through Azure AI Foundry credentials (from .env)
      AZURE_AI_FOUNDRY_ENDPOINT: ${AZURE_AI_FOUNDRY_ENDPOINT}
      AZURE_AI_FOUNDRY_API_KEY: ${AZURE_AI_FOUNDRY_API_KEY}
      AZURE_DEPLOYMENT_NAME: ${AZURE_DEPLOYMENT_NAME:-gpt-4o}
      AZURE_API_VERSION: ${OPENAI_API_VERSION:-2024-12-01-preview}
      # Database URL for paias application (use Docker service name, not localhost)
      # Separate from Windmill's DATABASE_URL to avoid conflicts
      PAIAS_DATABASE_URL: postgresql+asyncpg://postgres:postgres@postgres:5432/paias
      # Telemetry - traces go to Jaeger, logs go to Loki
      OTEL_EXPORTER_OTLP_ENDPOINT: http://jaeger:4317
      OTEL_EXPORTER_OTLP_TRACES_ENDPOINT: http://jaeger:4317
      OTEL_EXPORTER_OTLP_LOGS_ENDPOINT: http://loki:3100/otlp/v1/logs
      OTEL_SERVICE_NAME: ${OTEL_SERVICE_NAME:-paias}
      OTEL_SAMPLING_RATE: ${OTEL_SAMPLING_RATE:-1.0}
      # Web search configuration
      WEBSEARCH_ENGINE: ${WEBSEARCH_ENGINE:-duckduckgo}
      WEBSEARCH_MAX_RESULTS: ${WEBSEARCH_MAX_RESULTS:-10}
      WEBSEARCH_TIMEOUT_SECONDS: ${WEBSEARCH_TIMEOUT_SECONDS:-30}
      # Logging - enabled to send logs to Loki via OTLP
      ENABLE_AGENTIC_LOGGING: "true"
    depends_on:
      windmill_server:
        condition: service_healthy
      jaeger:
        condition: service_healthy
      loki:
        condition: service_started
    deploy:
      resources:
        limits:
          cpus: "1.0"
          memory: 2G
        reservations:
          cpus: "0.5"
          memory: 1G
    volumes:
      - windmill_worker_cache_2:/tmp/windmill/cache

volumes:
  postgres_data:
  windmill_worker_cache:
  windmill_worker_cache_2:
  loki_data:
  grafana_data:

